# This file is part of nullspace_optimizer. 
#
# It is a modification of the 2018-2019 version initially developed with the    
# copyright of CNRS, Ecole Polytechnique and Safran.
#
# This version is maintained by the research team of Prof. Florian Feppon 2023
# https://people.cs.kuleuven.be/~florian.feppon/software.html
#
# nullspace_optimizer is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 3 of the License, or
# (at your option) any later version.
#
# nullspace_optimizer is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# A copy of the GNU General Public License is included below.
# For further information, see <http://www.gnu.org/licenses/>.
import numpy as np
import scipy.sparse as sp

class Optimizable:
    r"""
    An abstract class for instantiating optimization problems solvable with     
    first-order gradient methods on general sets :math:`\mathcal{X}`.   
    An Optimizable object describes a
    constrained minimization problem of the form

    .. math::   
        
       \begin{aligned} \min_{x\in \mathcal{X}} & \quad      J(x) \\
       s.t. & \left\{\begin{aligned}
        g_i(x) & =0  \text{ for all }0 \leqslant i \leqslant p-1,\\
        h_j(x) & \leqslant 0 \text{ for all }0\leqslant j \leqslant q-1,\end{aligned}\right.
        \end{aligned}

    where :math:`p` and :math:`q` are the number of equality and inequality constraints. 
        
    Use rather the class :py:class:`~nullspace_optimizer.EuclideanOptimizable` if   
    :math:`\mathcal{X}=\mathbb{R}^n` is a finite dimensional vector space with fixed dimension.
        
    An :py:class:`~nullspace_optimizer.Optimizable`
    object should implement the following structure:
    
    .. code:: python
    
       from nullspace_optimizer import Optimizable
    
       class MyOptimizable(Optimizable):
           # Initialization
           def x0(self):
               pass
    
           # Objective function
           def J(self, x):
               pass
    
           # Equality constraints
           def G(self, x):
               pass
    
           # Inequality constraints
           def H(self, x):
               pass
    
           # Derivative of the objective function
           def dJ(self, x):
               pass
    
           # Jacobian matrix of G
           def dG(self, x):
               pass
    
           # Jacobian matrix of H
           def dH(self, x):
               pass
    
           # Inner product metrizing the optimization set
           def inner_product(self, x):
               pass
    
           # Retraction 
           def retract(self, x, dx):
               pass
    
           # Post processing every time a   
           # point on the optimization path is accepted
           def accept(self, params, results):
               pass
    """

    def x0(self):
        """
        :return: Initial value for the optimization algorithm.     
                  The variable ``x``  of the other methods should have the  
                  same format. 
        """
        return None

    def J(self, x):
        """  
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
                    
        :return: Value of the objective function at the point ``x``.    
        :rtype: float 
        """
        return None

    def G(self, x):
        """
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
                    
        :return: List ``[g1,g2,...,gp]`` or `numpy array <https://numpy.org/doc/stable/reference/generated/numpy.array.html>`_   
                 with the floating values of the :math:`p` equality constraints.       
                 
        .. note::   
            
           This method needs not to be implemented if there are no equality constraints.
        """
        return []

    def H(self, x):
        """
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
                    
        :return: List ``[h1,h2,...,hq]``    
                 or  
                 `numpy array <https://numpy.org/doc/stable/reference/generated/numpy.array.html>`_   
                 with the floating values 
                 of the :math:`q` inequality constraints    
                 of equality constraints.       
                 
        .. note::   
            
           This method needs not to be implemented if there are no inequality constraints."""
        return []

    def dJ(self, x):
        r""" 
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    

        :return: :math:`n` dimensional list or numpy array with the value of the (Fréchet) derivative   
                 of ``J`` at ``x``.
                    
        .. note::   
            
           The derivative should be compatible with the retraction :py:meth:`~nullspace_optimizer.Optimizable.retract`  
           in that the following asymptotic expansion should hold:

           .. math::

              \texttt{J}(\texttt{retract}(\texttt{x},h\times\texttt{dx}))=\texttt{J}(\texttt{x})+     
              h \times \texttt{DJ}(\texttt{x})^{T}\texttt{dx} +o(h) \text{ as }
              h\rightarrow 0, 
        """
        return np.array([])

    def dG(self, x):
        r""" 
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
                    
        :return: Jacobian matrix :math:`(\partial_j g_i(\texttt{x}))_{\substack{1\leqslant i\leqslant p\\ 1\leqslant j\leqslant n}}`  
                 of the :math:`p` equality constraints given as a   
                 :math:`p\times n` matrix where    
                 :math:`n` is the length of ``dJ(x)``.                     

        :rtype: either a list of :math:`p` lists with :math:`n` entries each, or a  
                :math:`p\times   n` 
                `numpy array <https://numpy.org/doc/stable/reference/generated/numpy.array.html>`_,    
                or a 
                :math:`p\times n`  
                sparse matrix in the `scipy csc format <https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html>`_.

        .. note::

           The Fréchet derivative should be compatible with the retraction :py:meth:`~nullspace_optimizer.Optimizable.retract`  
           in that the following asymptotic expansion should hold:

           .. math::

              \texttt{G}(\texttt{retract}(\texttt{x},h\times\texttt{dx}))=\texttt{G}(\texttt{x})+     
              h \times \texttt{DG}(\texttt{x})\texttt{dx} +o(h) \text{ as }
              h\rightarrow 0, 

        .. note::   
            
           This method needs not to be implemented if there are no equality constraints.
        """
        return []

    def dH(self, x):
        r""" 
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
                    
        :return: Jacobian matrix :math:`(\partial_j h_i(\texttt{x}))_{\substack{1\leqslant i\leqslant q\\ 1\leqslant j\leqslant n}}`  
                 of the :math:`q` inequality constraints given as a   
                 :math:`q\times n` matrix where    
                 :math:`n` is the length of ``dJ(x)``.                     

        :rtype: either a list of :math:`q` lists with :math:`n` entries each, or a  
                :math:`q\times   n` 
                `numpy array <https://numpy.org/doc/stable/reference/generated/numpy.array.html>`_,    
                or a 
                :math:`q\times n`  
                sparse matrix in the `scipy csc format <https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html>`_.

        .. note::

           The Fréchet derivative should be compatible with the retraction :py:meth:`~nullspace_optimizer.Optimizable.retract`  
           in that the following asymptotic expansion should hold:

           .. math::

              \texttt{H}(\texttt{retract}(\texttt{x},h\times\texttt{dx}))=\texttt{H}(\texttt{x})+     
              h \times \texttt{DH}(\texttt{x})\texttt{dx} +o(h) \text{ as }
              h\rightarrow 0, 

        .. note::   
            
           This method needs not to be implemented if there are no inequality constraints.
        """
        return []

    def inner_product(self, x):
        r""" 
        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by :py:meth:`~nullspace_optimizer.Optimizable.retract`.    
            
        :return: Inner product matrix that metrizes the tangent space   
                 (the set of derivatives ``dx``) at `x`.
                 It should be a :math:`n\times n`  sparse matrix    
                 in the `scipy csc format <https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html>`_  
                 where :math:`n`    
                 is the length of ``dJ(x)``.
        """
        return sp.csc_matrix((0,0))

    def retract(self, x, dx):
        """
        The retraction that explicit how to move from `x` by a step `dx`
        to obtain the new optimization point.

        :param x: Current design variable generated by :py:meth:`~nullspace_optimizer.Optimizable.x0`   
                  or by a previous call to the function     
                  :py:meth:`~nullspace_optimizer.Optimizable.retract`.    

        :param dx: an update step provided by the optimizer, that is a vector   
                   of length `n` where :math:`n`    
                   is the length of ``dJ(x)``.

        :return: The new design variable after the update step ``dx``.
        """
        return None

    def accept(self, params, results):
        """
        This function is called by :py:meth:`~nullspace_optimizer.nlspace_solve`:

        - at the initialization
        - every time a new design variable ``x`` is accepted on the optimization
          trajectory

        Implementing this method is useful to perform some post processing operations   
        at the **beginning** of every iteration of the optimization algorithm,  
        such as saving the current design variable in an appropriate folder.  
        The function does not return any output but
        may update the dictionaries ``params`` or ``results``   
        which may affect the optimization.

        Notably, the current optimization point is stored in the variable
        ``results['x'][-1]``
        and an update of its value will be taken into account by :py:meth:`~nullspace_optimizer.nlspace_solve`  
        (although this is not recommended). This can be useful if the design variable is the    
        name of a file that is moved to a different folder.

        :param params: dictionary of algorithm parameters,  
                       that are reloaded at every iteration if changed. Changing the values of this     
                       dictionary is not recommended but could be useful if the user desires to     
                       implement continuation schemes.

        :param results: the current dictionary of `results`
                        that is returned by the routine     
                        :py:meth:`~nullspace_optimizer.nlspace_solve`
        """
        pass




\section{Session 4: Numerical methods}
\subsection{SLERP - Part II}
Applying a trigonometric equivalence to the SLERP method, a new function $\Psi_{n+1}$, can be computed from Eq. (\ref{E:alpha}) as:
\begin{equation}\label{E:slerp_theta}
	\begin{array}{c}
		\Psi_{n+1}=f(\Psi_{n}, g_n) \\
		\Psi_{n+1}=\frac{1}{\sin \theta_n}\left[\sin((1-k_n)\theta_n)\Psi_{n}+\sin(k_n\theta_n)\frac{g_n}{||g_n||}\right]\\
		\theta_n=\cos^{-1} \left(\frac{(\Psi_{n},g_n)}{||g_n||,||\Psi_{n}||}\right) 
	\end{array}
\end{equation}
\subsection{Constraint optimization}
In the topology optimization problem, constraints have been defined in terms of the design variable, $ \chi $ or $ \rho $, and fixed to a certain value. Let $ c(\rho) $ be a function such that:
\begin{equation}
c(\rho) =\int x d\Omega-V=0
\end{equation}
Where $x$ is the design variable and $ V $ is the volume of the domain. Therefore, the topology optimization problem can be written in terms of $ c(x) $
\begin{equation}
\begin{array}{cc}
\min &J(x)\\
x & \\
s.t. & c(x)=0\\
\end{array}
\end{equation}
\subsection{Satelle-point Lagrangian}
Let $\mathcal{L}$ be a function such that:
\begin{equation}
	\mathcal{L}(x,\lambda)=J(x)+\lambda c(x)
\end{equation}
Where $ c(x) $ is the constraint function and $ J(x) $ is the energy deformation. $\mathcal{L}$ is defined as the Lagranian function. Therefore, the topology optimization problem can be defined as:
\begin{equation}
\begin{array}{ccc}
\max &\min & \mathcal{L}(x,\lambda)\\
\lambda & x & \\
\end{array}
\end{equation}
The dependence of the function in terms of the constraint is evaluated as a partial derivative of $\mathcal{L}$:
\begin{equation}
\frac{\partial \mathcal{L}}{\partial c}=\lambda 
\rightarrow
\left\{
\begin{array}{cc}
\lambda > 0 & \text{high dependence on c}\\
\lambda < 0 & \text{low dependence on c}\\
\lambda = 0 & \text{no dependence on c} 
\end{array}\right.
 \end{equation}
No dependence on the constraint $ c $can be interpreted as an indicator of which constraint may be removed.
\subsection{KKT}
KKT problem is defined as follows:
\begin{equation}
\left.
\begin{array}{c}
\frac{\partial \mathcal{L}}{\partial x}=\frac{\partial J}{\partial x}+\lambda\frac{\partial c}{\partial x}=0\\
\frac{\partial \mathcal{L}}{\partial \lambda}=c(x)=0
\end{array}
\right\}\rightarrow
F(x,\lambda)=0
\end{equation}
This function gives the stationary points of function  $ \mathcal{L} $ in terms of $x$ and $ \lambda $.
\subsection{Augmented Lagrangian}
The Augmented Lagranian is an extension of the Lagranian function $ \mathcal{L} $, which is defined as follows:
\begin{equation}\label{eq:aug_lagraninan}
\mathcal{L}_u(x,\lambda)=J(x)+\lambda c(x)+\frac{1}{2}\mu c(x)^2
\end{equation}
And its gradient:
\begin{eqnarray}
&	F_x=\frac{\partial \mathcal{L}}{\partial x}=\frac{\partial J}{\partial x}+\lambda\frac{\partial c}{\partial x}+\mu c(x)\frac{\partial c}{\partial x}=0\\
&	F_{\lambda}=\frac{\partial \mathcal{L}}{\partial \lambda}=c(x)=0
\end{eqnarray}

